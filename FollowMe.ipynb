{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "985dcf71-633b-497d-8974-7e6716f0ab36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "utils.common\n",
      "\n",
      "Modules to skip:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport utils.common\n",
    "\n",
    "%aimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3aa45669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e8e7073-bcd4-44d1-8f77-e6abc4f6ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "from pathlib import Path\n",
    "from utils.common import (\n",
    "    download_file,\n",
    "    read_file_from_zip,\n",
    "    bulk_insert_df\n",
    ")\n",
    "from orm.amazon_products import (\n",
    "    session_scope,\n",
    "    Product, ProductScalars\n",
    ")\n",
    "from sqlalchemy import select"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f7687c-b4d5-4575-879d-8a5d6343a1a6",
   "metadata": {},
   "source": [
    "# Download the data\n",
    "- If you have trouble with this, just get it from the website directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ccb95d9-20bf-4dba-bfe7-900e6689e104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloads/amazon-sales-dataset.zip\n",
      "File downloaded to: Downloads/amazon-sales-dataset.zip\n"
     ]
    }
   ],
   "source": [
    "kaggle_url = 'https://www.kaggle.com/api/v1/datasets/download/karkavelrajaj/amazon-sales-dataset'\n",
    "local_file =  'Downloads/amazon-sales-dataset.zip'\n",
    "print(local_file)\n",
    "\n",
    "download_file(kaggle_url, local_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e9f051-5af8-4bbb-bfd8-299999865fe4",
   "metadata": {},
   "source": [
    "# Parse out what we need\n",
    "- the only columns we care about are product_id, product_name, category, rating, rating count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ced39bc-5c0a-4d92-9697-226a54166d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    read_file_from_zip(zip_path=local_file, file_name='amazon.csv'),\n",
    "    sep=',',\n",
    "    quoting=csv.QUOTE_MINIMAL,\n",
    "    usecols=['product_id', 'product_name', 'category', 'rating', 'rating_count'],\n",
    "    dtype='string'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6f72d5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_id                                       product_name  \\\n",
      "0  B07JW9H4J1  Wayona Nylon Braided USB to Lightning Fast Cha...   \n",
      "1  B098NS6PVG  Ambrane Unbreakable 60W / 3A Fast Charging 1.5...   \n",
      "2  B096MSW6CT  Sounce Fast Phone Charging Cable & Data Sync U...   \n",
      "3  B08HDJ86NZ  boAt Deuce USB 300 2 in 1 Type-C & Micro USB S...   \n",
      "4  B08CF3B7N1  Portronics Konnect L 1.2M Fast Charging 3A 8 P...   \n",
      "\n",
      "                                            category rating rating_count  \n",
      "0  Computers&Accessories|Accessories&Peripherals|...    4.2       24,269  \n",
      "1  Computers&Accessories|Accessories&Peripherals|...    4.0       43,994  \n",
      "2  Computers&Accessories|Accessories&Peripherals|...    3.9        7,928  \n",
      "3  Computers&Accessories|Accessories&Peripherals|...    4.2       94,363  \n",
      "4  Computers&Accessories|Accessories&Peripherals|...    4.2       16,905  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0f2f3a-8791-4845-ba64-30ae3b286b2d",
   "metadata": {},
   "source": [
    "## To simplify the problem let's assume we only care about the top level category ( delimted by | ) so extract that before continuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "550f5fef-6bfe-4cd7-9508-72e95afc44ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_id                                       product_name  \\\n",
      "0  B07JW9H4J1  Wayona Nylon Braided USB to Lightning Fast Cha...   \n",
      "1  B098NS6PVG  Ambrane Unbreakable 60W / 3A Fast Charging 1.5...   \n",
      "2  B096MSW6CT  Sounce Fast Phone Charging Cable & Data Sync U...   \n",
      "3  B08HDJ86NZ  boAt Deuce USB 300 2 in 1 Type-C & Micro USB S...   \n",
      "4  B08CF3B7N1  Portronics Konnect L 1.2M Fast Charging 3A 8 P...   \n",
      "\n",
      "                category rating rating_count  \n",
      "0  Computers&Accessories    4.2       24,269  \n",
      "1  Computers&Accessories    4.0       43,994  \n",
      "2  Computers&Accessories    3.9        7,928  \n",
      "3  Computers&Accessories    4.2       94,363  \n",
      "4  Computers&Accessories    4.2       16,905  \n"
     ]
    }
   ],
   "source": [
    "df[\"category\"] = df[\"category\"].str.split(\"|\").str[0].astype(\"string\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75af7671",
   "metadata": {},
   "source": [
    "### Remove non numeric values from ratings_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152ffb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up comma in ratings_count\n",
    "df[\"rating_count\"] = (\n",
    "    df[\"rating_count\"]\n",
    "    .astype(str)  # Convert all values to strings\n",
    "    .str.replace(\",\", \"\", regex=True)  # Remove commas\n",
    "    .replace(\"<NA>\", \"0\")  # Explicitly replace Pandas <NA> values\n",
    "    .fillna(\"0\")  # Ensure any remaining NaNs are replaced\n",
    "    .astype(\"int64\")  # Convert to integer\n",
    ")\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa670a8",
   "metadata": {},
   "source": [
    "### Remove non integers from  ratings columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ca3b51bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      product_id                                       product_name  \\\n",
      "1279  B08L12N5H1  Eureka Forbes car Vac 100 Watts Powerful Sucti...   \n",
      "\n",
      "          category rating rating_count  \n",
      "1279  Home&Kitchen    NaN          992  \n"
     ]
    }
   ],
   "source": [
    "df[\"rating\"] = (\n",
    "    df[\"rating\"]\n",
    "    .astype(str)\n",
    "    .replace(\"|\",np.nan) \n",
    "    )# Explicitly replace Pandas <NA> values\n",
    "\n",
    "print(df[df[\"product_id\"] == \"B08L12N5H1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3de8b0-789d-4a1f-a49e-c988bb92fb46",
   "metadata": {},
   "source": [
    "## What EDA would you do to figure out what the DDL in your database should be regarding things like primary key uniqueness, reasonable varchar lengths, numeric precision, nullability etc...?\n",
    "- If PK violations might occur, maybe just keep the first occurence for simplicity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "89bbf68b-0453-416a-97e1-852b9a08c82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any duplicates by product_id: True\n",
      "      product_id  count\n",
      "261   B077Z65HSD      3\n",
      "939   B09KLVMZ3B      3\n",
      "848   B098NS6PVG      3\n",
      "522   B083342NKJ      3\n",
      "519   B082T6V3DT      3\n",
      "...          ...    ...\n",
      "457   B07WHS7MZ1      1\n",
      "456   B07WHQWXL7      1\n",
      "455   B07WHQBZLS      1\n",
      "454   B07WGPKTS4      1\n",
      "1350  B0BR4F878Q      1\n",
      "\n",
      "[1351 rows x 2 columns]\n",
      "Any duplicates by product_id: False\n"
     ]
    }
   ],
   "source": [
    "# check to see if there are dubes by product_id\n",
    "has_duplicates = df[\"product_id\"].duplicated().any()\n",
    "print(f\"Any duplicates by product_id: {has_duplicates}\")\n",
    "\n",
    "#Show counts of product id\n",
    "product_counts = df.groupby(\"product_id\").size().reset_index(name=\"count\")\n",
    "product_counts = product_counts.sort_values(by=\"count\", ascending=False)\n",
    "print(product_counts)\n",
    "\n",
    "# drop duplicates\n",
    "df_unique = df.drop_duplicates(subset=\"product_id\", keep=\"first\")\n",
    "\n",
    "#confirm no duplicates in has_duplicates df\n",
    "has_duplicates = df_unique[\"product_id\"].duplicated().any()\n",
    "print(f\"Any duplicates by product_id: {has_duplicates}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0ff6123a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Data Type  Max Length\n",
      "product_id      string          10\n",
      "product_name    string         485\n",
      "rating          object           3\n",
      "rating_count    object           6\n",
      "category        string          21\n"
     ]
    }
   ],
   "source": [
    "# Get the data types\n",
    "data_types = df[[\"product_id\", \"product_name\", \"rating\", \"rating_count\", \"category\"]].dtypes\n",
    "\n",
    "# Get the max length of each column\n",
    "max_lengths = df[[\"product_id\", \"product_name\", \"rating\", \"rating_count\", \"category\"]].apply(lambda x: x.astype(str).str.len().max())\n",
    "\n",
    "# output\n",
    "result = pd.DataFrame({\n",
    "    \"Data Type\": data_types,\n",
    "    \"Max Length\": max_lengths\n",
    "})\n",
    "\n",
    "print(result)\n",
    "\n",
    "# I realized when I created \"top level category\" column, it needed to be explicitly cast to string. I updated that up above and reran.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32beb415-e6a9-4127-8f78-d335ad24b280",
   "metadata": {},
   "source": [
    "# What type coercions do you need to ensure compatibility with your ORM model / DB tables?   If there's any bad data, maybe set it to null?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b840c3d2-4e5d-4f27-9a36-3d83783b3a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " product_id      0\n",
      "product_name    0\n",
      "category        0\n",
      "rating          1\n",
      "rating_count    0\n",
      "dtype: int64\n",
      "NaN Values:\n",
      " product_id      0\n",
      "product_name    0\n",
      "category        0\n",
      "rating          1\n",
      "rating_count    0\n",
      "dtype: int64\n",
      "Unique Values Per Column:\n",
      " product_id      1351\n",
      "product_name    1337\n",
      "category           9\n",
      "rating            27\n",
      "rating_count    1144\n",
      "dtype: int64\n",
      "Unique Categories in top_level_category:\n",
      "<StringArray>\n",
      "['Computers&Accessories',           'Electronics',    'MusicalInstruments',\n",
      "        'OfficeProducts',          'Home&Kitchen',       'HomeImprovement',\n",
      "            'Toys&Games',         'Car&Motorbike',   'Health&PersonalCare']\n",
      "Length: 9, dtype: string\n",
      "\n",
      "Descriptive Statistics for Numeric Columns:\n",
      "        product_id                                       product_name  \\\n",
      "count         1465                                               1465   \n",
      "unique        1351                                               1337   \n",
      "top     B07JW9H4J1  Fire-Boltt Ninja Call Pro Plus 1.83\" Smart Wat...   \n",
      "freq             3                                                  5   \n",
      "\n",
      "           category rating rating_count  \n",
      "count          1465   1464         1465  \n",
      "unique            9     27         1144  \n",
      "top     Electronics    4.1         9378  \n",
      "freq            526    244            9  \n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)\n",
    "\n",
    "nan_values = df.isna().sum()\n",
    "print(\"NaN Values:\\n\", nan_values)\n",
    "\n",
    "unique_values = df.nunique()\n",
    "print(\"Unique Values Per Column:\\n\", unique_values)\n",
    "\n",
    "print(\"Unique Categories in top_level_category:\")\n",
    "print(df[\"category\"].unique())\n",
    "\n",
    "print(\"\\nDescriptive Statistics for Numeric Columns:\")\n",
    "print(df.describe())  # Provides stats like min, max, mean, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624fb7ef-3492-4c13-b931-bd2bcc941eff",
   "metadata": {},
   "source": [
    "# Now, we want to separate our data into two tables compatible with your ORM models / foreign key relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8a2beb72-d28b-4a6e-a993-5c2e2adb6458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Products DataFrame\n",
    "df_products = df[[\"product_id\", \"product_name\"]].drop_duplicates()\n",
    "\n",
    "# Create ProductScalars DataFrame\n",
    "df_scalars = df[[\"product_id\", \"category\", \"rating\", \"rating_count\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5031a353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_id                                       product_name\n",
      "0  B07JW9H4J1  Wayona Nylon Braided USB to Lightning Fast Cha...\n",
      "1  B098NS6PVG  Ambrane Unbreakable 60W / 3A Fast Charging 1.5...\n",
      "2  B096MSW6CT  Sounce Fast Phone Charging Cable & Data Sync U...\n",
      "3  B08HDJ86NZ  boAt Deuce USB 300 2 in 1 Type-C & Micro USB S...\n",
      "4  B08CF3B7N1  Portronics Konnect L 1.2M Fast Charging 3A 8 P...\n"
     ]
    }
   ],
   "source": [
    "print(df_products.head())\n",
    "#print(df_scalars.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13329e37-710e-4a9b-8cec-c4152d041eb7",
   "metadata": {},
   "source": [
    "# Bulk Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f55a822",
   "metadata": {},
   "source": [
    "### Create Prodcut table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85890e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session connected as: postgresql://brett:mypassword@localhost:5432/amazon_products_db\n",
      "âœ… Table 'product' exists in the database.\n"
     ]
    }
   ],
   "source": [
    "with session_scope() as session:\n",
    "    # Create table if it doesn't exist\n",
    "    qry_create = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS product (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            product_id VARCHAR(10) UNIQUE NOT NULL,\n",
    "            product_name VARCHAR(500) NOT NULL,\n",
    "            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "        )\n",
    "    \"\"\"\n",
    "    session.execute(qry_create)\n",
    "    session.commit()  # Commit the transaction\n",
    "\n",
    "    # Check if the table exists\n",
    "    qry_check = \"\"\"\n",
    "        SELECT EXISTS (\n",
    "            SELECT 1 FROM information_schema.tables \n",
    "            WHERE table_name = 'product'\n",
    "        )\n",
    "    \"\"\"\n",
    "    result = session.execute(qry_check).scalar()\n",
    "\n",
    "    if result:\n",
    "        print(\"Table 'product' exists in the database.\")\n",
    "    else:\n",
    "        print(\"Table 'product' was not created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5af7d74",
   "metadata": {},
   "source": [
    "### Create product_scalar table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6b39be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session connected as: postgresql://brett:mypassword@localhost:5432/amazon_products_db\n",
      "Table 'product' exists in the database.\n"
     ]
    }
   ],
   "source": [
    "with session_scope() as session:\n",
    "    # Create table if it doesn't exist\n",
    "    qry_create = \"\"\"\n",
    "        CREATE TABLE product_scalars (\n",
    "            id serial primary key,\n",
    "            product_id VARCHAR(10),\n",
    "            category VARCHAR(255) NOT NULL,\n",
    "            rating numeric(3,\n",
    "                2\n",
    "            ) CHECK (\n",
    "                rating BETWEEN 0\n",
    "                AND 5\n",
    "            ),\n",
    "            rating_count INT CHECK (\n",
    "                rating_count >= 0\n",
    "            ),\n",
    "            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            foreign key (product_id) references products(product_id)\n",
    "        )\"\"\"\n",
    "    session.execute(qry_create)\n",
    "    session.commit()  # Commit the transaction\n",
    "\n",
    "    # Check if the table exists\n",
    "    qry_check = \"\"\"\n",
    "        SELECT EXISTS (\n",
    "            SELECT 1 FROM information_schema.tables \n",
    "            WHERE table_name = 'products'\n",
    "        )\n",
    "    \"\"\"\n",
    "    result = session.execute(qry_check).scalar()\n",
    "\n",
    "    if result:\n",
    "        print(\"Table 'product' exists in the database.\")\n",
    "    else:\n",
    "        print(\"Table 'product' was not created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be33fee0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1006f97-274f-4c78-8fab-ecb7c6160ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session connected as: postgresql://brett:mypassword@localhost:5432/amazon_products_db\n"
     ]
    }
   ],
   "source": [
    "# Use the engine to bulk insert data\n",
    "bulk_insert_df(df_products, Products)\n",
    "bulk_insert_df(df_scalars, ProductScalars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77045324-1ec7-492e-bfdb-a8cafba1e61c",
   "metadata": {},
   "source": [
    "# Queries\n",
    "- Show me (in Pandas, SQL & SQLAlchemy how you'd get the rating average by category, but weigthed by the rating count, i.e. if the rating has a higher rating count, it is weighted proportionally within the category)\n",
    "- Show me a couple other interesting queries, using SQL and/or Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6f1715-4857-491f-a056-b658cf1cc6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# I could not get the ORM query to work, so changed it to this.\n",
    "with session_scope() as session:\n",
    "    qry = \"SELECT * FROM product_scalars\"\n",
    "    df_db = pd.read_sql_query(qry, con=session.connection(),\n",
    "        index_col='product_id',\n",
    "        dtype={\n",
    "            'product_id': 'string',\n",
    "            'category': 'string',\n",
    "            'rating': 'Float64',\n",
    "            'rating_count': 'Int64'\n",
    "        })\n",
    "    print(df_db.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "18700fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                category  weighted_avg_rating\n",
      "5        HomeImprovement             4.349346\n",
      "7         OfficeProducts             4.327161\n",
      "8             Toys&Games             4.300000\n",
      "1  Computers&Accessories             4.230489\n",
      "2            Electronics             4.150944\n",
      "4           Home&Kitchen             4.090941\n",
      "3    Health&PersonalCare             4.000000\n",
      "6     MusicalInstruments             3.954506\n",
      "0          Car&Motorbike             3.800000\n",
      "Session connected as: postgresql://brett:mypassword@localhost:5432/amazon_products_db\n",
      "                       weighted_avg_rating\n",
      "category                                  \n",
      "HomeImprovement                   4.349346\n",
      "OfficeProducts                    4.327161\n",
      "Toys&Games                             4.3\n",
      "Computers&Accessories             4.230489\n",
      "Electronics                       4.150944\n",
      "Home&Kitchen                      4.090941\n",
      "Health&PersonalCare                    4.0\n",
      "MusicalInstruments                3.954506\n",
      "Car&Motorbike                          3.8\n"
     ]
    }
   ],
   "source": [
    "df_scalars[\"rating\"] = pd.to_numeric(df_scalars[\"rating\"], errors=\"coerce\")\n",
    "df_scalars[\"rating_count\"] = pd.to_numeric(df_scalars[\"rating_count\"], errors=\"coerce\")\n",
    "\n",
    "df_weighted_avg_pd = (\n",
    "    df_scalars.groupby(\"category\")\n",
    "    .apply(lambda x: (x[\"rating\"] * x[\"rating_count\"]).sum() / x[\"rating_count\"].sum())\n",
    "    .reset_index(name=\"weighted_avg_rating\")\n",
    ")\n",
    "\n",
    "print(df_weighted_avg_pd.sort_values(by=\"weighted_avg_rating\", ascending=False))\n",
    "\n",
    "\n",
    "\n",
    "with session_scope() as session:\n",
    "    qry = \"\"\"SELECT \n",
    "                category,\n",
    "                SUM(rating * rating_count) / SUM(rating_count) AS weighted_avg_rating\n",
    "            FROM product_scalars\n",
    "            GROUP BY category\n",
    "            ORDER BY 2 DESC\"\"\"\n",
    "            \n",
    "    df_weighted_avg_sql = pd.read_sql_query(qry, con=session.connection(),\n",
    "        index_col='category',\n",
    "        dtype={\n",
    "            \n",
    "            'category': 'string',\n",
    "            'weighted_avg_rating': 'Float64',\n",
    "            \n",
    "        })\n",
    "    print(df_weighted_avg_sql)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b10aff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session connected as: postgresql://brett:mypassword@localhost:5432/amazon_products_db\n",
      "Empty DataFrame\n",
      "Columns: [product_name]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# check to see if there are any records in Products that don't have records in ProductScalars\n",
    "with session_scope() as session:\n",
    "    qry = \"\"\"SELECT \n",
    "                p.product_id,p.product_name\n",
    "                \n",
    "            FROM products p\n",
    "            left outer join product_scalars ps on p.product_id = ps.product_id\n",
    "            where ps.product_id is null\n",
    "            ORDER BY 2 DESC\"\"\"\n",
    "            \n",
    "    df_check_for_missing_joins = pd.read_sql_query(qry, con=session.connection(),\n",
    "        index_col='product_id',\n",
    "        dtype={\n",
    "            \n",
    "            'product_id': 'string',\n",
    "            'product_name': 'Float64',\n",
    "            \n",
    "        })\n",
    "    print(df_check_for_missing_joins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7c7737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                category  rating_count\n",
      "0            Electronics        426973\n",
      "1           Home&Kitchen        270563\n",
      "2  Computers&Accessories        253105\n"
     ]
    }
   ],
   "source": [
    "# Get the top 3 categories\n",
    "\n",
    "df_top_categories = (\n",
    "    df_scalars.groupby(\"category\")[\"rating_count\"]\n",
    "    .max() \n",
    "    .nlargest(3)  \n",
    "    .reset_index() \n",
    ")\n",
    "\n",
    "print(df_top_categories)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".challenge2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
